{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create_synthetic_MNIST_datasets.py.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2ytSi2lG0EnmFZekqg8++",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zar1Z/non-iid-dataset-for-personalized-federated-learning/blob/master/create_synthetic_MNIST_datasets_py.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUlQa3zETRLz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"This code to create a custom MNIST dataset was made possible thanks to\n",
        "\n",
        " https://github.com/LaRiffle/collateral-learning . \n",
        "\n",
        " \n",
        "\n",
        "Important to know that aside the tampering I did on the build_dataset function\n",
        "\n",
        "for my own application, I also had to change rgba_to_rgb. Indeed, the function\n",
        "\n",
        "was working as desired on Jupyter but not on Spyder. Do not ask me why !\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "\n",
        "import math\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"PLOT FUNCTIONS TO VISUALIZE THE FONTS AND DATASETS\"\"\"\n",
        "\n",
        "def show_original_font(family:str):\n",
        "\n",
        "    \"\"\"Plot the original numbers used to create the dataset\"\"\"\n",
        "\n",
        "    \n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    plt.title(family)\n",
        "\n",
        "    plt.text(0, 0.4, '1234567890', size=50, family=family)\n",
        "\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(f\"plots/{family}_original.png\") \n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "def convert_to_rgb(data):\n",
        "\n",
        "    \n",
        "\n",
        "    def rgba_to_rgb(rgba):\n",
        "\n",
        "        return rgba[1:]\n",
        "\n",
        "\n",
        "\n",
        "    return np.apply_along_axis(rgba_to_rgb, 2, data) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def elastic_transform(image, alpha, sigma, random_state=None):\n",
        "\n",
        "    \"\"\"Elastic deformation of images as described in [Simard2003]_.\n",
        "\n",
        "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
        "\n",
        "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
        "\n",
        "       Proc. of the International Conference on Document Analysis and\n",
        "\n",
        "       Recognition, 2003.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if random_state is None:\n",
        "\n",
        "        random_state = np.random.RandomState(None)\n",
        "\n",
        "\n",
        "\n",
        "    shape = np.array([28, 28, 3], dtype =int)\n",
        "\n",
        "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
        "\n",
        "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
        "\n",
        "\n",
        "\n",
        "    x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]))\n",
        "\n",
        "    #print(x.shape, y.shape, z.shape)\n",
        "\n",
        "    #print(dx.shape, dy.shape)\n",
        "\n",
        "    #x, y, z = x[:28, :28, :3], y[:28, :28, :3], z[:28, :28, :3]\n",
        "\n",
        "    #dx, dy = dx[:28, :28, :3], dy[:28, :28, :3]\n",
        "\n",
        "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
        "\n",
        "\n",
        "\n",
        "    distored_image = map_coordinates(image, indices, order=1, mode='reflect')\n",
        "\n",
        "    return distored_image.reshape(shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def center(data):\n",
        "\n",
        "    # Inverse black and white\n",
        "\n",
        "    wb_data = np.ones(data.shape) * 255 - data\n",
        "\n",
        "    \n",
        "\n",
        "    # normalize\n",
        "\n",
        "    prob_data = wb_data / np.sum(wb_data)\n",
        "\n",
        "    \n",
        "\n",
        "    # marginal distributions\n",
        "\n",
        "    dx = np.sum(prob_data, (1, 2))\n",
        "\n",
        "    dy = np.sum(prob_data, (0, 2))\n",
        "\n",
        "\n",
        "\n",
        "    # expected values\n",
        "\n",
        "    (X, Y, Z) = prob_data.shape\n",
        "\n",
        "    cx = np.sum(dx * np.arange(X))\n",
        "\n",
        "    cy = np.sum(dy * np.arange(Y))\n",
        "\n",
        "    \n",
        "\n",
        "    # Check bounds\n",
        "\n",
        "    assert cx > X/4 and cx < 3 * X/4, f\"ERROR: {cx} > {X/4} and {cx} < {3 * X/4}\"\n",
        "\n",
        "    assert cy > Y/4 and cy < 3 * Y/4, f\"ERROR: {cy} > {Y/4} and {cy} < {3 * Y/4}\"\n",
        "\n",
        "    \n",
        "\n",
        "    # print('Center', cx, cy)\n",
        "\n",
        "    \n",
        "\n",
        "    x_min = int(round(cx - X/4))\n",
        "\n",
        "    x_max = int(round(cx + X/4))\n",
        "\n",
        "    y_min = int(round(cy - Y/4))\n",
        "\n",
        "    y_max = int(round(cy + Y/4))\n",
        "\n",
        "    \n",
        "\n",
        "    return data[x_min:x_max, y_min:y_max, :]\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_transformed_digit(digit:int, size:float, rotation:float, family:str):\n",
        "\n",
        "    \n",
        "\n",
        "    fig = plt.figure(figsize=(2,2), dpi=28)\n",
        "\n",
        "    fig.text(0.4, 0.4, str(digit), size=size, rotation=rotation, family=family)\n",
        "\n",
        "\n",
        "\n",
        "    # Rm axes, draw and get the rgba shape of the digit\n",
        "\n",
        "    plt.axis('off')\n",
        "\n",
        "    fig.canvas.draw()\n",
        "\n",
        "    data = np.frombuffer(fig.canvas.tostring_argb(), dtype=np.uint8)\n",
        "\n",
        "    data = data.reshape(fig.canvas.get_width_height()[::-1] + (4,))\n",
        "\n",
        "\n",
        "\n",
        "    # Convert to rgb\n",
        "\n",
        "    data = convert_to_rgb(data)\n",
        "\n",
        "\n",
        "\n",
        "    # Center the data\n",
        "\n",
        "    data = center(data)\n",
        "\n",
        "\n",
        "\n",
        "    # Apply an elastic deformation\n",
        "\n",
        "    data = elastic_transform(data, alpha=991, sigma=9)\n",
        "\n",
        "\n",
        "\n",
        "    # Free memory space\n",
        "\n",
        "    plt.close(fig)\n",
        "\n",
        "    \n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def save_dataset(dataset_name:str, array_X:np.array, array_y:np.array):\n",
        "\n",
        "    \n",
        "\n",
        "    with open(f'{dataset_name}.pkl', 'wb') as output:\n",
        "\n",
        "        dataset = array_X, array_y\n",
        "\n",
        "        pickle.dump(dataset, output)\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "def build_dataset(C:dict, std_size=2.5):\n",
        "\n",
        "    \"\"\"build a dataset with `dataset_size` according to the chosen font\n",
        "\n",
        "    and deformation. Only digits in `datasets_digits` are in the created \n",
        "\n",
        "    dataset.\"\"\"\n",
        "\n",
        "    \n",
        "\n",
        "    numbers_str=\"\".join([str(n) for n in C['numbers']])\n",
        "\n",
        "    file_name=f\"{C['font']}_{numbers_str}_{C['n_samples']}_{C['tilt']}_{C['seed']}\"    \n",
        "\n",
        "    \n",
        "\n",
        "    if os.path.isfile(f\"{file_name}.pkl\"):\n",
        "\n",
        "        return pickle.load(open(f\"{file_name}.pkl\", \"rb\"))\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "    if C['seed']: np.random.seed(C['seed'])\n",
        "\n",
        "    \n",
        "\n",
        "    #Make a plot of each original digit to know what they look like\n",
        "\n",
        "#    show_original_font(C['font'])\n",
        "\n",
        "    \n",
        "\n",
        "    list_X = []\n",
        "\n",
        "    list_y= []\n",
        "\n",
        "    \n",
        "\n",
        "    for i in range(C['n_samples']):\n",
        "\n",
        "        \n",
        "\n",
        "        if i%10 == 0: print(round(i / C['n_samples'] * 100), '%')\n",
        "\n",
        "        \n",
        "\n",
        "        X = np.zeros((3, 28, 28 ))\n",
        "\n",
        "        #Choosing a number at this step and its transformation characteristics\n",
        "\n",
        "        digit = C[\"numbers\"][np.random.randint(len(C[\"numbers\"]))]\n",
        "\n",
        "\n",
        "\n",
        "        for j, tilt in enumerate(C['tilt']):\n",
        "\n",
        "        \trotation = tilt + np.random.normal(0, C['std_tilt'])\n",
        "\n",
        "        \tsize = 60 + np.random.normal(0, std_size)         \t\n",
        "\n",
        "\n",
        "\n",
        "        \tX_tilt=create_transformed_digit(digit, size, rotation, C['font'])\n",
        "\n",
        "\n",
        "\n",
        "        \tX[j] = X_tilt[:, :, j]\n",
        "\n",
        "\n",
        "\n",
        "        # Append data to the datasets\n",
        "\n",
        "        #list_X.append(X[:,:,0])\n",
        "\n",
        "        list_X.append(X)\n",
        "\n",
        "        list_y.append([digit])\n",
        "\n",
        "    \n",
        "\n",
        "    #save the dataset\n",
        "\n",
        "    dataset = (np.array(list_X), np.array(list_y))\n",
        "\n",
        "    pickle.dump(dataset, open(f'{file_name}.pkl', 'wb'))\n",
        "\n",
        "    \n",
        "\n",
        "    return np.array(list_X), np.array(list_y)\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "class Ds_MNIST_modified(Dataset):\n",
        "\n",
        "    \"\"\"Creation of the dataset used to create the clients' dataloader\"\"\"\n",
        "\n",
        "    \n",
        "\n",
        "    def __init__(self, features, labels):\n",
        "\n",
        "        self.features = features\n",
        "\n",
        "        self.labels = labels\n",
        "\n",
        "    \n",
        "\n",
        "    def __len__(self): return len(self.features)\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        \n",
        "\n",
        "        #3D input 1x28x28\n",
        "\n",
        "        sample_x = torch.Tensor(self.features[idx])\n",
        "\n",
        "        sample_y = self.labels[idx]\n",
        "\n",
        "        \n",
        "\n",
        "        return sample_x, sample_y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_samples(self, channel:int, title=None, plot_name=\"\", \n",
        "\n",
        "        n_examples =20):\n",
        "\n",
        "    \n",
        "\n",
        "        n_rows = int(n_examples / 5)\n",
        "\n",
        "        plt.figure(figsize=(1* n_rows, 1*n_rows))\n",
        "\n",
        "        if title: plt.suptitle(title)\n",
        "\n",
        "            \n",
        "\n",
        "        for idx in range(n_examples):\n",
        "\n",
        "            \n",
        "\n",
        "            X, y = self[idx]\n",
        "\n",
        "\n",
        "\n",
        "            ax = plt.subplot(n_rows, 5, idx + 1)\n",
        "\n",
        "\n",
        "\n",
        "            image = 255 - X.view((-1, 28, 28))[channel]\n",
        "\n",
        "            ax.imshow(image, cmap='gist_gray')\n",
        "\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "\n",
        "\n",
        "        if plot_name!=\"\":plt.savefig(f\"plots/\"+plot_name+\".png\")\n",
        "\n",
        "\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def get_synth_MNIST(clients, batch_size:int, shuffle=True):\n",
        "\n",
        "    \"\"\"function returning a list of training and testing dls.\"\"\"\n",
        "\n",
        "    \n",
        "\n",
        "    list_train, list_test = [], []\n",
        "\n",
        "    \n",
        "\n",
        "    for C in clients:\n",
        "\n",
        "        X, y = build_dataset(C)\n",
        "\n",
        "        X = (255 - X) /255\n",
        "\n",
        "\n",
        "\n",
        "        X_train, y_train = X[:C['n_samples_train']], y[:C['n_samples_train']]\n",
        "\n",
        "        X_test, y_test = X[C['n_samples_train']:], y[C['n_samples_train']:]\n",
        "\n",
        "            \n",
        "\n",
        "        train_ds = Ds_MNIST_modified(X_train, y_train)         \n",
        "\n",
        "        train_dl = DataLoader(train_ds, batch_size = batch_size, shuffle = shuffle)\n",
        "\n",
        "        list_train.append(train_dl)\n",
        "\n",
        "         \n",
        "\n",
        "        test_ds = Ds_MNIST_modified(X_test, y_test)         \n",
        "\n",
        "        test_dl = DataLoader(test_ds, batch_size = batch_size, shuffle = shuffle)  \n",
        "\n",
        "        list_test.append(test_dl)\n",
        "\n",
        "        \n",
        "\n",
        "    return list_train, list_test\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "eFGGEUGgTZka"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}